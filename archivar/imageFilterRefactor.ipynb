{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "directorio = \"/home/maucasco/Documents/maestria/proyecto_grado/pujc-advocato-filter-project-mngr/assets\"\n",
    "def eliminar_sombras(image):\n",
    "\n",
    "\n",
    "# Ecualizar el histograma\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    tophat = cv2.morphologyEx(image, cv2.MORPH_TOPHAT, kernel)\n",
    "\n",
    "    # Mejorar el contraste después de la transformación 'top-hat'\n",
    "    result = cv2.add(image, tophat)\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "def eliminar_texto(imagen, x_inicio, y_inicio, x_fin, y_fin):\n",
    "    mascara = np.zeros_like(imagen[:, :, 0])\n",
    "    mascara[y_inicio:y_fin, x_inicio:x_fin] = 255\n",
    "    dilatada = cv2.dilate(mascara, (1,1), iterations = 2)  # Dilatar para cubrir más región del texto\n",
    "    return cv2.inpaint(imagen, dilatada, inpaintRadius=3, flags=cv2.INPAINT_TELEA)\n",
    "\n",
    "def mejorar_contraste(imagen):\n",
    "    # Ecualización del histograma\n",
    "    ecualizada = cv2.equalizeHist(imagen)\n",
    "    \n",
    "    # Ajuste de contraste y brillo\n",
    "    contraste = 1.5  # Factor de contraste (mayor que 1 aumenta el contraste)\n",
    "    brillo = 30      # Ajuste de brillo\n",
    "    mejorada = cv2.convertScaleAbs(ecualizada, alpha=contraste, beta=brillo)\n",
    "    \n",
    "    # Filtro bilateral para suavizar el ruido manteniendo los bordes\n",
    "    filtrada = cv2.bilateralFilter(mejorada, 9, 75, 75)\n",
    "    \n",
    "    return filtrada\n",
    "\n",
    "def segmentar_imagen(imagen_sin_texto):\n",
    "   \n",
    "   \n",
    "    \n",
    "    # Eliminar sombras\n",
    "    imagen_sin_texto= eliminar_sombras(imagen_sin_texto)\n",
    "    imagen_gris = cv2.cvtColor(imagen_sin_texto, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Usar thresholding de Otsu\n",
    "    _, imagen_segmentada = cv2.threshold(imagen_gris, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Detección de contornos y conservar solo el contorno más grande\n",
    "    contours, _ = cv2.findContours(imagen_segmentada, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Filtrar contornos por área\n",
    "    min_area = 3000  # Puedes ajustar este valor\n",
    "    contours = [c for c in contours if cv2.contourArea(c) > min_area]\n",
    "    \n",
    "    mask = np.zeros_like(imagen_gris)\n",
    "    if contours:\n",
    "        # Ordenar contornos y dibujar el más grande\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "        cv2.drawContours(mask, [contours[0]], -1, (255), thickness=cv2.FILLED)\n",
    "    \n",
    "    aguacate = cv2.bitwise_and(imagen_gris, imagen_gris, mask=mask)\n",
    "    \n",
    "    # Mejorar el contraste y brillo del aguacate\n",
    "    aguacate_resaltado = mejorar_contraste(aguacate)\n",
    "    \n",
    "    return aguacate_resaltado\n",
    "\n",
    "# Carga y preprocesamiento\n",
    "def redimensionar(image):\n",
    "   original_height, original_width = image.shape[:2]\n",
    "   desired_width = 100\n",
    "\n",
    "# Calcula el factor de escala y el alto deseado\n",
    "   scale_factor = desired_width / original_width\n",
    "   desired_height = 130\n",
    "\n",
    "# Redimensiona la imagen proporcionalmente\n",
    "   resized_img = cv2.resize(image, (desired_width, desired_height))\n",
    "\n",
    "\n",
    "   return resized_img\n",
    "\n",
    "def procesar_imagen(ruta_imagen,nombre):\n",
    "    imagen = cv2.imread(ruta_imagen)[100:, :]\n",
    "\n",
    "    imagen_sin_texto=[]\n",
    "    print(\"Type:\",type(imagen))\n",
    "    print(\"Shape of Image:\", imagen.shape)\n",
    "    print('Total Number of pixels:', imagen.size)\n",
    "    print(\"Image data type:\",imagen.dtype)\n",
    "        # print(\"Pixel Values:\\n\", img)\n",
    "    print(\"Dimension:\", imagen.ndim)\n",
    "\n",
    "\n",
    "    if imagen.size>1000000:\n",
    "        imagen_sin_texto = eliminar_texto(imagen, 0, 0, 3000, 250)\n",
    "    elif imagen.size>10000000:\n",
    "        imagen_sin_texto = eliminar_texto(imagen, 0, 0, 3000, 1000)\n",
    "    else:\n",
    "        imagen_sin_texto = eliminar_texto(imagen, 0, 0, 3000, 500)    \n",
    "        \n",
    "    aguacate_solo = segmentar_imagen(imagen_sin_texto)\n",
    "    redimenciada = redimensionar(aguacate_solo)\n",
    "    nuevaImga=directorio+'/process/fil_'+nombre\n",
    "    print(nuevaImga)\n",
    "    cv2.imwrite(nuevaImga, redimenciada)\n",
    "    return imagen, imagen_sin_texto, aguacate_solo,redimenciada\n",
    "\n",
    "\n",
    "def mostrar_imagenes(titulos, imagenes):\n",
    "    count = len(titulos)\n",
    "    for i in range(count):\n",
    "        plt.subplot(1, count, i + 1)\n",
    "        plt.title(titulos[i])\n",
    "        plt.imshow(imagenes[i], cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "archivos = os.listdir(directorio)\n",
    "for archivo in archivos:\n",
    "    if archivo.endswith(\".jpg\"):\n",
    "        ruta_imagen = os.path.join(directorio, archivo)\n",
    "        titulos = [\"Ori\", \"SinTex\",\"Sinsomb\", archivo]\n",
    "        imagenes = procesar_imagen(ruta_imagen,archivo)\n",
    "        mostrar_imagenes(titulos, imagenes)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular histograma\n",
    "def mostrar_histograma(img):\n",
    "    histogram = cv2.calcHist([img], [0], None, [256], [0,256])\n",
    "\n",
    "    # Graficar histograma\n",
    "    plt.figure()\n",
    "    plt.title(\"Histograma de Intensidad\")\n",
    "    plt.xlabel(\"Valor de pixel\")\n",
    "    plt.ylabel(\"Número de píxeles\")\n",
    "    plt.plot(histogram)\n",
    "    plt.xlim([0, 256])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def mostrar_densidad(pixels,archivo):\n",
    "\n",
    "    # Crear el gráfico de densidad\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.kdeplot(pixels, bw_adjust=0.5, shade=True)\n",
    "\n",
    "    plt.title('Gráfico de Densidad de Valores de Píxeles'+archivo)\n",
    "    plt.xlabel('Valor del Píxel')\n",
    "    plt.ylabel('Densidad')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def createDataset():\n",
    "    archivos = os.listdir(directorio+'/process')\n",
    "    print(archivos)\n",
    "    data = []\n",
    "    labels = []\n",
    "    dimensiones = []\n",
    "    for archivo in archivos:\n",
    "        if archivo.endswith(\".jpg\"):\n",
    "            ruta_imagen = os.path.join(directorio+'/process/', archivo)\n",
    "            print(ruta_imagen)\n",
    "            img = cv2.imread(ruta_imagen)\n",
    "            #mostrar_histograma(img)\n",
    "            if img is not None:\n",
    "                print(directorio+'/process'+archivo)\n",
    "                flattened = img.flatten()\n",
    "                data.append(flattened)\n",
    "                mostrar_densidad(flattened,archivo)\n",
    "                dimensiones.append(img.shape)\n",
    "                # Aquí necesitas una forma de obtener la etiqueta para cada imagen\n",
    "                # Ejemplo: si el nombre del archivo indica la clase\n",
    "                if \"sano\" in archivo:\n",
    "                    labels.append(0)\n",
    "                else:\n",
    "                    labels.append(1)\n",
    "    return data , labels, dimensiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "data , labels, dimensiones =createDataset()\n",
    "\n",
    "\n",
    "\n",
    "X = np.array(data)\n",
    "dims = np.array(dimensiones)\n",
    "df_data = pd.DataFrame(X)\n",
    "\n",
    "# Agregar columnas para dimensiones\n",
    "df_data['height'] = dims[:, 0]\n",
    "df_data['width'] = dims[:, 1]\n",
    "# Guardar el DataFrame como CSV (opcional)\n",
    "df_data.to_csv(os.path.join(directorio, 'dataset_imagenes.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Definir el modelo\n",
    "model = Sequential()\n",
    "\n",
    "# Añadir una capa convolucional con 32 filtros, un kernel de 3x3, activación ReLU y entrada especificada\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100,100, 1))) # Asegúrate de que input_shape coincida con las dimensiones de tus imágenes\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Añadir más capas convolucionales y de pooling según sea necesario\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Aplanar el resultado para alimentar una DNN\n",
    "model.add(Flatten())\n",
    "\n",
    "# Añadir capas densas (fully connected)\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Añadir Dropout para evitar overfitting\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Capa de salida con activación softmax para clasificación multiclase\n",
    "model.add(Dense(10, activation='softmax')) # Cambia el número de neuronas a la cantidad de tus clases\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Ver la arquitectura del modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Crear generadores de datos de imagen\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Suponiendo que tus datos están en un directorio llamado 'data' con subdirectorios 'train' y 'test'\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'assets/traint',\n",
    "    target_size=(100, 100),\n",
    "    color_mode='grayscale',  # o 'rgb' si tus imágenes son a color\n",
    "    batch_size=32,\n",
    "    class_mode='sparse')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    '/home/maucasco/Documents/maestria/proyecto_grado/pujc-advocato-filter-project-mngr/assets/test',\n",
    "    target_size=(100, 100),\n",
    "    color_mode='grayscale',  # o 'rgb' si tus imágenes son a color\n",
    "    batch_size=32,\n",
    "    class_mode='sparse')\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // test_generator.batch_size,\n",
    "    epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
